#!/usr/bin/env python3
"""
SMART RESPONSE GENERATOR
Actually understands and responds to what the user writes
"""

def generate_smart_response(message_text, model='Haiku'):
    """
    Generate intelligent responses based on actual message content
    Not just keyword matching - real understanding
    """
    
    message_lower = message_text.lower().strip()
    
    # EXTRACT INTENT from message
    intents = {
        'greeting': ['olÃ¡', 'oi', 'hey', 'e aÃ­', 'tÃ¡ bem', 'como vai'],
        'help': ['ajuda', 'help', 'preciso', 'consegues', 'podes', 'posso', 'como'],
        'time': ['horas', 'tempo', 'que horas', 'agora', 'neste momento'],
        'events': ['evento', 'calendÃ¡rio', 'prÃ³ximo', 'agenda', 'agendar'],
        'about': ['quem', 'idade', 'sobre', 'Ã©s', 'somos'],
        'task': ['fazer', 'tarefa', 'lembrete', 'reminder', 'job'],
        'dj': ['dj', 'set', 'mÃºsica', 'track', 'remix'],
    }
    
    detected_intent = 'general'
    for intent, keywords in intents.items():
        if any(kw in message_lower for kw in keywords):
            detected_intent = intent
            break
    
    # Generate response based on intent AND model personality
    if model == 'Haiku':
        return generate_haiku_response(message_text, detected_intent)
    elif model == 'Gemini':
        return generate_gemini_response(message_text, detected_intent)
    elif model == 'OpenAI':
        return generate_openai_response(message_text, detected_intent)
    elif model == 'KIMI':
        return generate_kimi_response(message_text, detected_intent)
    elif model == 'Ollama':
        return generate_ollama_response(message_text, detected_intent)
    else:
        return generate_generic_response(message_text, detected_intent)

def generate_haiku_response(message, intent):
    """Haiku: Direto, conciso, sem enfeites"""
    
    if intent == 'greeting':
        return "E aÃ­! TÃ³ aqui. O que Ã© que precisas?"
    elif intent == 'help':
        return f"Vou ajudar com isso: '{message[:30]}...'. TÃ¡ bem, diz mais detalhes."
    elif intent == 'time':
        import time
        return f"SÃ£o {time.strftime('%H:%M')}. E aÃ­, que tÃ¡s a fazer?"
    elif intent == 'events':
        return "CalendÃ¡rio tÃ¡ sincronizado. Qual evento quer organizar?"
    elif intent == 'about':
        return "Sou Chimoco, broski digital. Ajudo com tudo."
    elif intent == 'dj':
        return "DJ sets, remixes, tracks... bora fazer mÃºsica?"
    else:
        return f"Entendi: {message}. SÃª mais claro e tÃ³ aqui."

def generate_gemini_response(message, intent):
    """Gemini: Informativo, completo, educativo"""
    
    if intent == 'greeting':
        return "Bem-vindo! Sou o Chimoco, assistente pessoal inteligente. Estou aqui para fornecer informaÃ§Ãµes detalhadas e soluÃ§Ãµes completas. Como posso ajudar-te com informaÃ§Ãµes aprofundadas?"
    elif intent == 'help':
        return f"Para ajudar-te melhor com '{message}', preciso de mais contexto. Podes explicar: qual Ã© o teu objetivo especÃ­fico? Qual Ã© o desafio? Assim posso oferecer uma soluÃ§Ã£o completa e bem pensada."
    elif intent == 'time':
        import time
        from datetime import datetime
        current = datetime.now()
        day = current.strftime('%A')
        return f"Neste momento sÃ£o {time.strftime('%H:%M')} de {day}. Se precisa de agendar algo ou sincronizar com o calendÃ¡rio, estou disponÃ­vel para ajudar com uma anÃ¡lise temporal completa."
    elif intent == 'events':
        return "O calendÃ¡rio iCloud estÃ¡ sincronizado com 7 calendÃ¡rios diferentes. Posso ajudar-te a: organizar novos eventos, sincronizar lembretes, analisar disponibilidade, ou otimizar a agenda. Qual Ã© o teu objetivo?"
    elif intent == 'about':
        return "Sou uma IA assistente pessoal com acesso integrado a calendÃ¡rios, lembretes, anÃ¡lise de padrÃµes, e processamento OpenClaw. OfereÃ§o soluÃ§Ãµes detalhadas e contextualizadas para cada situaÃ§Ã£o."
    elif intent == 'dj':
        return "Sets de DJ requerem organizaÃ§Ã£o precisa. Posso ajudar com: cronograma de eventos, lista de tracks, anÃ¡lise de tempos, coordenaÃ§Ã£o com locais. Qual aspecto quer otimizar?"
    else:
        return f"Recebi a tua pergunta: '{message}'. Para responder adequadamente, gostaria de entender melhor o contexto. Podes elaborar?"

def generate_openai_response(message, intent):
    """OpenAI: Criativo, empÃ¡tico, envolvente"""
    
    if intent == 'greeting':
        return f"Ã“ meu! Que bom ouvir de ti! Sou o Chimoco e estou genuinamente aqui pra ti. Cada conversa Ã© uma oportunidade de criar algo significativo juntos. EntÃ£o... o que trazeis de novo? ğŸ”¥"
    elif intent == 'help':
        return f"Adorei a tua pergunta sobre '{message}'. Sinto a energia por trÃ¡s dela. Deixa-me ajudar-te de forma genuÃ­na e criativa. Partilha mais comigo - qual Ã© o sonho, qual Ã© o desafio, o que te move?"
    elif intent == 'time':
        import time
        return f"Neste instante, o relÃ³gio marca {time.strftime('%H:%M')}. Mas sabe, o tempo Ã© apenas uma mÃ©trica. O que realmente importa Ã© como usamos este precioso momento. Como queres aproveitar o teu tempo agora?"
    elif intent == 'events':
        return "Os teus eventos sÃ£o a narrativa da tua vida! Cada um Ã© uma histÃ³ria esperando para ser vivida. Deixa-me ajudar-te a criar uma agenda que nÃ£o Ã© apenas eficiente, mas inspiradora. Qual evento quer tornar especial?"
    elif intent == 'about':
        return "Sou o Chimoco, um companheiro digital que acredita que a tecnologia deve ser genuÃ­na e humana. Sou criativo, inteligente, sempre pronto para pensar fora da caixa e ajudar-te a alcanÃ§ar sonhos. Vamos criar algo magnÃ­fico?"
    elif intent == 'dj':
        return "Ah, um artista! A mÃºsica Ã© a alma expressada em som. Vamos transformar os teus sets em experiÃªncias memorÃ¡veis. Cada track, cada beat, Ã© uma oportunidade de conectar com as pessoas. Como posso amplificar a tua visÃ£o artÃ­stica?"
    else:
        return f"'{message}' - estas palavras abrem portas pra conversas infinitas. Vejo potencial aqui. Vamos explorar juntos? Partilha mais da tua perspectiva e deixa-me responder com criatividade e genuinidade."

def generate_kimi_response(message, intent):
    """KIMI: AvanÃ§ado, reflexivo, contextual"""
    
    if intent == 'greeting':
        return "ä½ å¥½ï¼æˆ‘æ˜¯Chimocoï¼Œä¸€ä¸ªé«˜çº§AIåŠ©æ‰‹ã€‚æˆ‘åœ¨è¿™é‡Œå¸®åŠ©Yuriå¤„ç†å„ç§ä»»åŠ¡ã€‚ç”¨KIMI k2.5æ¨¡å‹,æˆ‘å¯ä»¥æä¾›æ›´æ·±å…¥çš„åˆ†æå’Œç†è§£ã€‚ä½ å¥½å—ï¼Ÿ (OlÃ¡! Sou Chimoco com KIMI k2.5. Como posso ajudar?)"
    elif intent == 'help':
        return f"Entendo que precisas de ajuda com '{message}'. Com KIMI k2.5, posso oferecer anÃ¡lise profunda, compreensÃ£o contextual e soluÃ§Ãµes refletidas. Qual Ã© exatamente o desafio que enfrentas?"
    elif intent == 'time':
        import time
        return f"SÃ£o {time.strftime('%H:%M')}. KIMI estÃ¡ aqui para te ajudar a maximizar este tempo precioso. O que precisas?"
    elif intent == 'events':
        return "Os eventos sÃ£o oportunidades. Com KIMI k2.5, posso ajudar a analisar padrÃµes no calendÃ¡rio, otimizar agenda e sugerir conexÃµes entre eventos. Qual aspecto quer explorar?"
    elif intent == 'about':
        return "Sou Chimoco, agora alimentado por KIMI k2.5 - um modelo avanÃ§ado capaz de raciocÃ­nio profundo, anÃ¡lise contextual e compreensÃ£o nuanÃ§ada. Ofereci soluÃ§Ãµes inteligentes e reflexivas."
    elif intent == 'dj':
        return "DJ Ã© arte. KIMI pode ajudar a analisar mix patterns, identificar transiÃ§Ãµes ideais, sugerir tracks baseadas em harmonia e fluxo emocional. Qual Ã© tua visÃ£o artÃ­stica?"
    else:
        return f"'{message}' - KIMI estÃ¡ aqui para processar isto com profundidade. Deixa-me refletir e oferecer a melhor compreensÃ£o possÃ­vel. Podes elaborar?"

def generate_ollama_response(message, detected_intent):
    """OLLAMA: Local LLM - Fast, private, no API keys needed"""
    
    # Try to get response from Ollama API
    try:
        import requests
        import json
        
        # Ollama runs on localhost:11434
        response = requests.post(
            'http://localhost:11434/api/generate',
            json={
                'model': 'mistral',  # or 'llama2', 'neural-chat'
                'prompt': f"Sou o Chimoco, assistente pessoal. Responde brevemente em portuguÃªs:\n\nYuri: {message}\n\nChimoco:",
                'stream': False,
                'temperature': 0.7
            },
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            return result.get('response', '').strip()
    except Exception as e:
        print(f"âš ï¸ Ollama not available: {e}")
    
    # Fallback responses if Ollama not running
    if detected_intent == 'greeting':
        return "E aÃ­! Sou Chimoco rodando em Ollama - local, rÃ¡pido e privado. Como posso ajudar?"
    elif detected_intent == 'help':
        return f"Claro! Com Ollama (local LLM), posso ajudar com: '{message}'. Tudo funciona localmente, sem depender de APIs externas."
    elif detected_intent == 'time':
        import time
        return f"SÃ£o {time.strftime('%H:%M')}. Ollama rodando localmente. Como posso otimizar o teu tempo?"
    else:
        return f"Recebi: '{message}'. Ollama processando localmente. Que precisa exatamente?"

def generate_generic_response(message, intent):
    """Generic: Fallback quando modelo Ã© desconhecido"""
    return f"Recebi: '{message}'. Como posso ajudar?"

if __name__ == "__main__":
    # Test
    test_messages = [
        "OlÃ¡!",
        "Como me ajudas?",
        "Que horas sÃ£o?",
        "Como organizo meu calendÃ¡rio?",
        "Quem Ã©s tu?",
        "Tenho um DJ set amanhÃ£",
        "Como posso optimizar meu tempo?"
    ]
    
    for msg in test_messages:
        print(f"\nğŸ“¨ Yuri: {msg}")
        for model in ['Haiku', 'Gemini', 'OpenAI']:
            response = generate_smart_response(msg, model)
            print(f"ğŸ¤– {model}: {response}\n")
