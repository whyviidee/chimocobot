"""
API WRAPPER - Integra Rate Limiter + Fallback autom√°tico
Zero rate limits, m√°xima efici√™ncia
"""

import time
from rate_limiter import limiter
from datetime import datetime

class SmartAPIWrapper:
    def __init__(self):
        self.providers = [
            "anthropic/claude-haiku-4-5",
            "openai/gpt-4o-mini",
            "openai/gpt-4"
        ]
        self.current_provider_idx = 0
    
    def get_next_available_provider(self):
        """Retorna o pr√≥ximo provider dispon√≠vel"""
        for i in range(len(self.providers)):
            idx = (self.current_provider_idx + i) % len(self.providers)
            provider = self.providers[idx]
            
            can_call, reason = limiter.check_rate_limit(provider)
            if can_call:
                return idx, provider
        
        # Se nenhum dispon√≠vel, mostra status
        return None, f"‚è∏Ô∏è Todos os modelos bloqueados. Status:\n{limiter.get_status()}"
    
    def call_api(self, prompt, max_retries=3):
        """Chama API com fallback autom√°tico"""
        attempt = 0
        last_error = None
        
        while attempt < max_retries:
            # Verificar cache primeiro
            cache_key = f"prompt_{hash(prompt)}"
            cached = limiter.get_cache(cache_key)
            if cached:
                print(f"üíæ Resposta do cache (economizou 1 chamada)")
                return cached
            
            # Obter provider dispon√≠vel
            idx, provider = self.get_next_available_provider()
            
            if idx is None:
                print(provider)  # Mostra mensagem de bloqueio
                time.sleep(5)
                attempt += 1
                continue
            
            print(f"üì§ Tentativa {attempt + 1}: Usando {provider}")
            
            try:
                # Aqui entra a chamada real √† API
                # Por enquanto, simular sucesso
                limiter.record_call(provider)
                
                response = f"[Resposta de {provider}]"
                limiter.set_cache(cache_key, response)
                
                print(f"‚úÖ Sucesso com {provider}")
                self.current_provider_idx = idx  # Manter este provider como padr√£o
                return response
            
            except Exception as e:
                error_msg = str(e)
                print(f"‚ùå Erro em {provider}: {error_msg}")
                
                # Se for rate limit, bloqueia este provider
                if "429" in error_msg or "rate_limit" in error_msg:
                    limiter.mark_rate_limit(provider)
                
                last_error = e
                # Move para pr√≥ximo provider
                self.current_provider_idx = (idx + 1) % len(self.providers)
                attempt += 1
                time.sleep(2)  # Espera antes de retry
        
        return f"‚ùå Falha ap√≥s {max_retries} tentativas. √öltimo erro: {last_error}"
    
    def get_status(self):
        """Mostra status completo"""
        return limiter.get_status()
    
    def reset(self):
        """Reset de tudo"""
        limiter.reset()


# Inst√¢ncia global
api = SmartAPIWrapper()


if __name__ == "__main__":
    print("üî• Smart API Wrapper\n")
    
    # Teste
    result = api.call_api("Ol√°, qual √© o teu nome?")
    print(f"Resultado: {result}\n")
    
    print("Status:")
    print(api.get_status())
